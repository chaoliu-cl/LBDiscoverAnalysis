% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/performance_optimalization.R
\name{vec_preprocess}
\alias{vec_preprocess}
\title{Vectorized preprocessing of text}
\usage{
vec_preprocess(
  text_data,
  text_column = "abstract",
  remove_stopwords = TRUE,
  custom_stopwords = NULL,
  min_word_length = 3,
  max_word_length = 50,
  chunk_size = 100
)
}
\arguments{
\item{text_data}{A data frame containing text data.}

\item{text_column}{Name of the column containing text to process.}

\item{remove_stopwords}{Logical. If TRUE, removes stopwords.}

\item{custom_stopwords}{Character vector of additional stopwords to remove.}

\item{min_word_length}{Minimum word length to keep.}

\item{max_word_length}{Maximum word length to keep.}

\item{chunk_size}{Number of documents to process in each chunk.}
}
\value{
A data frame with processed text.
}
\description{
This function preprocesses text data using vectorized operations for better performance.
}
\examples{
\dontrun{
processed_data <- vec_preprocess(article_data, text_column = "abstract")
}
}
